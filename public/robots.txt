# robots.txt
# Location: public/robots.txt
# This file tells search engines which pages they can and cannot crawl

# Allow all search engines to crawl the site
User-agent: *
Allow: /

# Disallow private and sensitive pages
Disallow: /api/
Disallow: /auth/
Disallow: /profile
Disallow: /dash-board
Disallow: /chat/
Disallow: /_next/
Disallow: /admin/

# Allow specific public pages (optional, but helps clarify)
Allow: /auth/login-and-signup
Allow: /*.css
Allow: /*.js

# Crawl-delay (optional - helps reduce server load)
# Crawl-delay: 10

# Sitemap location
Sitemap: https://skill-swaps-mydeployments.vercel.app/sitemap.xml