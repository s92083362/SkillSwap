# robots.txt
# Location: public/robots.txt
# This file tells search engines which pages they can and cannot crawl

# Allow all search engines to crawl the site
User-agent: *
Allow: /

# Disallow private and sensitive pages
Disallow: /api/
Disallow: /profile
Disallow: /dash-board
Disallow: /chat/
Disallow: /_next/
Disallow: /admin/

# Allow specific auth pages BEFORE blocking the rest
Allow: /auth/login-and-signup$
Disallow: /auth/

# Allow assets
Allow: /*.css
Allow: /*.js

# Sitemap location
Sitemap: https://skill-swaps.vercel.app/sitemap.xml